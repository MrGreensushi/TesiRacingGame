{
    "My Behavior": {
        "checkpoints": [
            {
                "steps": 1499981,
                "file_path": "results\\LongTrain2\\My Behavior\\My Behavior-1499981.onnx",
                "reward": 83.42828726023436,
                "creation_time": 1669553084.1183984,
                "auxillary_file_paths": [
                    "results\\LongTrain2\\My Behavior\\My Behavior-1499981.pt"
                ]
            },
            {
                "steps": 1999975,
                "file_path": "results\\LongTrain2\\My Behavior\\My Behavior-1999975.onnx",
                "reward": 114.24348282814026,
                "creation_time": 1669553344.1811235,
                "auxillary_file_paths": [
                    "results\\LongTrain2\\My Behavior\\My Behavior-1999975.pt"
                ]
            },
            {
                "steps": 2499993,
                "file_path": "results\\LongTrain2\\My Behavior\\My Behavior-2499993.onnx",
                "reward": 117.96094965934753,
                "creation_time": 1669553607.7068665,
                "auxillary_file_paths": [
                    "results\\LongTrain2\\My Behavior\\My Behavior-2499993.pt"
                ]
            },
            {
                "steps": 2999989,
                "file_path": "results\\LongTrain2\\My Behavior\\My Behavior-2999989.onnx",
                "reward": 149.9350150624911,
                "creation_time": 1669553869.2540343,
                "auxillary_file_paths": [
                    "results\\LongTrain2\\My Behavior\\My Behavior-2999989.pt"
                ]
            },
            {
                "steps": 3000053,
                "file_path": "results\\LongTrain2\\My Behavior\\My Behavior-3000053.onnx",
                "reward": 149.9350150624911,
                "creation_time": 1669553869.3043778,
                "auxillary_file_paths": [
                    "results\\LongTrain2\\My Behavior\\My Behavior-3000053.pt"
                ]
            }
        ],
        "final_checkpoint": {
            "steps": 3000053,
            "file_path": "results\\LongTrain2\\My Behavior.onnx",
            "reward": 149.9350150624911,
            "creation_time": 1669553869.3043778,
            "auxillary_file_paths": [
                "results\\LongTrain2\\My Behavior\\My Behavior-3000053.pt"
            ]
        }
    },
    "metadata": {
        "stats_format_version": "0.3.0",
        "mlagents_version": "0.29.0",
        "torch_version": "1.7.1+cu110"
    }
}